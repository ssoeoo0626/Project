{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font', family='NanumGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 : `dataset.csv` $ \\rightarrow $ `X`, `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750, 40)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       2\n",
       "2       2\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "1745    2\n",
       "1746    2\n",
       "1747    2\n",
       "1748    2\n",
       "1749    2\n",
       "Length: 1750, dtype: int8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'dataset.csv'\n",
    "\n",
    "dataset = pd.read_csv(file)\n",
    "print(dataset.shape)\n",
    "# dataset.head().transpose()\n",
    "dataset['환매일종가위치'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop_info = ['종목코드', '기준가1', '녹인가1', '환매일 종가', '평가기준가']\n",
    "cols_drop_duplicate = ['평가구분', '상환조건달성'] + ['녹인발생차수'] # unique 값이 1개\n",
    "cols_drop_future = ['상환구분', '상환실현차수']\n",
    "\n",
    "cols_drop_dt = ['발행일', '상환일', '평가시작일', '평가종료일', '환매결정일', '녹인발생일']\n",
    "# 데이터 타입 변경\n",
    "for col in cols_drop_dt:\n",
    "    dataset[col] = pd.to_datetime(dataset[col])\n",
    "\n",
    "\n",
    "# 피처로 쓰기 애매함\n",
    "cols_cnt = [\n",
    "    '녹인일수', '녹인일수_전', '영업일수', '상환일수'\n",
    "]\n",
    "\n",
    "cols_feature = ['차수', '기초자산개수', '녹인발생차수_차이']\n",
    "cols_cat = ['환매일종가위치'] # 범주형 변수\n",
    "cols_dummy = ['환매일종가위치_code']\n",
    "dataset['환매일종가위치_code'] = dataset['환매일종가위치'].astype('category').cat.codes.astype(float)\n",
    "cols_pct100 = [\n",
    "    '상환조건(%)', '하한 수준(%)', '상환조건감소량(%)_prev', '상환조건감소량(%)_next',\n",
    "    '환매일 수준(%)', '녹인대비상환수준(%)', '환매대비상환수준(%)', '환매대비상환수준(%)_next'\n",
    "]\n",
    "cols_pct = [\n",
    "    '녹인비율', '녹인비율_전', 'H총증감률', 'H평균증감률', 'H일평균증감률', 'H이전대비증감률', '상환비율'\n",
    "]\n",
    "# 비율 단위 변경\n",
    "for col in cols_pct:\n",
    "    col_new = col+\"(%)\"\n",
    "    dataset[col_new] = dataset[col]*100\n",
    "    cols_pct100.append(col_new)\n",
    "\n",
    "#\n",
    "cols_drop = cols_drop_info + cols_drop_duplicate + cols_drop_future + cols_drop_dt + cols_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "'기초자산개수',\n",
    " '녹인발생차수_차이',\n",
    " '상환조건(%)',\n",
    " '상환조건감소량(%)_next',\n",
    " '환매일 수준(%)',\n",
    " '녹인대비상환수준(%)',\n",
    " '환매대비상환수준(%)_next',\n",
    " '녹인비율(%)',\n",
    " '녹인비율_전(%)',\n",
    " 'H총증감률(%)',\n",
    " 'H이전대비증감률(%)',\n",
    " '상환비율(%)'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1750, 13), (1750, 12), (1750,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# col_X = cols_feature + cols_pct100\n",
    "col_X = features\n",
    "col_y = 'label'\n",
    "\n",
    "df = dataset[col_X + [col_y]] # train + test(2015)\n",
    "\n",
    "X = dataset[col_X]\n",
    "y = dataset[col_y]\n",
    "\n",
    "df.shape, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트셋 : `dataset_test.csv` $\\rightarrow$ `X_test`, `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종목코드</th>\n",
       "      <th>차수</th>\n",
       "      <th>평가종료일</th>\n",
       "      <th>상환조건(%)</th>\n",
       "      <th>평가시작일</th>\n",
       "      <th>환매결정일</th>\n",
       "      <th>발행일</th>\n",
       "      <th>상환일</th>\n",
       "      <th>상환실현차수</th>\n",
       "      <th>녹인발생일</th>\n",
       "      <th>...</th>\n",
       "      <th>상환비율</th>\n",
       "      <th>녹인발생차수</th>\n",
       "      <th>녹인발생차수_차이</th>\n",
       "      <th>상환조건감소량(%)_prev</th>\n",
       "      <th>상환조건감소량(%)_next</th>\n",
       "      <th>녹인대비상환수준(%)</th>\n",
       "      <th>환매일 종가</th>\n",
       "      <th>환매일 수준(%)</th>\n",
       "      <th>환매대비상환수준(%)</th>\n",
       "      <th>환매대비상환수준(%)_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KR6DS0000428</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-03-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7893.759766</td>\n",
       "      <td>69.729595</td>\n",
       "      <td>15.270405</td>\n",
       "      <td>15.270405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KR6DS0000428</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2022-07-14</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-03-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6695.569824</td>\n",
       "      <td>59.145374</td>\n",
       "      <td>25.854626</td>\n",
       "      <td>20.854626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KR6DS0000428</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-07-13</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>2023-06-28</td>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-03-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6521.220215</td>\n",
       "      <td>57.605255</td>\n",
       "      <td>22.394745</td>\n",
       "      <td>17.394745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KR6HN0000H91</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-07-07</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2022-06-22</td>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>2024-01-09</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-03-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7335.000000</td>\n",
       "      <td>67.937237</td>\n",
       "      <td>17.062763</td>\n",
       "      <td>12.062763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KR6HN0000H91</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2022-07-08</td>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>2024-01-09</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-03-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6716.319824</td>\n",
       "      <td>62.206981</td>\n",
       "      <td>17.793019</td>\n",
       "      <td>12.793019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           종목코드  차수       평가종료일  상환조건(%)       평가시작일       환매결정일         발행일  \\\n",
       "0  KR6DS0000428   3  2022-07-13     85.0  2022-01-14  2022-06-28  2021-01-18   \n",
       "1  KR6DS0000428   4  2023-01-13     85.0  2022-07-14  2022-12-29  2021-01-18   \n",
       "2  KR6DS0000428   5  2023-07-13     80.0  2023-01-14  2023-06-28  2021-01-18   \n",
       "3  KR6HN0000H91   3  2022-07-07     85.0  2022-01-08  2022-06-22  2021-01-08   \n",
       "4  KR6HN0000H91   4  2023-01-06     80.0  2022-07-08  2022-12-22  2021-01-08   \n",
       "\n",
       "          상환일  상환실현차수       녹인발생일  ...  상환비율  녹인발생차수  녹인발생차수_차이  \\\n",
       "0  2024-01-17       6  2022-03-15  ...   0.0     3.0        0.0   \n",
       "1  2024-01-17       6  2022-03-15  ...   0.0     3.0        1.0   \n",
       "2  2024-01-17       6  2022-03-15  ...   0.0     3.0        2.0   \n",
       "3  2024-01-09       6  2022-03-09  ...   0.0     3.0        0.0   \n",
       "4  2024-01-09       6  2022-03-09  ...   0.0     3.0        1.0   \n",
       "\n",
       "   상환조건감소량(%)_prev  상환조건감소량(%)_next  녹인대비상환수준(%)       환매일 종가  환매일 수준(%)  \\\n",
       "0              5.0              0.0         30.0  7893.759766  69.729595   \n",
       "1             -0.0              5.0         25.0  6695.569824  59.145374   \n",
       "2              5.0              5.0         20.0  6521.220215  57.605255   \n",
       "3             -0.0              5.0         15.0  7335.000000  67.937237   \n",
       "4              5.0              5.0         10.0  6716.319824  62.206981   \n",
       "\n",
       "   환매대비상환수준(%)  환매대비상환수준(%)_next  \n",
       "0    15.270405         15.270405  \n",
       "1    25.854626         20.854626  \n",
       "2    22.394745         17.394745  \n",
       "3    17.062763         12.062763  \n",
       "4    17.793019         12.793019  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### test_set import #### \n",
    "import pandas as pd \n",
    "test_data = pd.read_csv('dataset_test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = test_data\n",
    "\n",
    "cols_drop_info = ['종목코드', '기준가1', '녹인가1', '환매일 종가', '평가기준가']\n",
    "cols_drop_duplicate = ['평가구분', '상환조건달성'] + ['녹인발생차수'] # unique 값이 1개\n",
    "cols_drop_future = ['상환구분', '상환실현차수']\n",
    "\n",
    "cols_drop_dt = ['발행일', '상환일', '평가시작일', '평가종료일', '환매결정일', '녹인발생일']\n",
    "# 데이터 타입 변경\n",
    "for col in cols_drop_dt:\n",
    "    dataset[col] = pd.to_datetime(dataset[col])\n",
    "\n",
    "\n",
    "# 피처로 쓰기 애매함\n",
    "cols_cnt = [\n",
    "    '녹인일수', '녹인일수_전', '영업일수', '상환일수'\n",
    "]\n",
    "\n",
    "cols_feature = ['차수', '기초자산개수', '녹인발생차수_차이']\n",
    "cols_cat = ['환매일종가위치'] # 범주형 변수\n",
    "cols_dummy = ['환매일종가위치_code']\n",
    "dataset['환매일종가위치_code'] = dataset['환매일종가위치'].astype('category').cat.codes.astype(float)\n",
    "cols_pct100 = [\n",
    "    '상환조건(%)', '하한 수준(%)', '상환조건감소량(%)_prev', '상환조건감소량(%)_next',\n",
    "    '환매일 수준(%)', '녹인대비상환수준(%)', '환매대비상환수준(%)', '환매대비상환수준(%)_next'\n",
    "]\n",
    "cols_pct = [\n",
    "    '녹인비율', '녹인비율_전', 'H총증감률', 'H평균증감률', 'H일평균증감률', 'H이전대비증감률', '상환비율'\n",
    "]\n",
    "# 비율 단위 변경\n",
    "for col in cols_pct:\n",
    "    col_new = col+\"(%)\"\n",
    "    dataset[col_new] = dataset[col]*100\n",
    "    cols_pct100.append(col_new)\n",
    "\n",
    "#\n",
    "cols_drop = cols_drop_info + cols_drop_duplicate + cols_drop_future + cols_drop_dt + cols_cat\n",
    "\n",
    "test_data = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((104, 13), (104, 12), (104,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_X = features\n",
    "col_y = 'label'\n",
    "\n",
    "test = test_data[col_X + [col_y]]\n",
    "\n",
    "X_test = test_data[col_X]\n",
    "y_test = test_data[col_y]\n",
    "\n",
    "test.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, random_state=42, \n",
    "    stratify= y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the selected columns and transform them\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[256  13]\n",
      " [  9  72]]\n",
      "Accuracy : 0.937\n",
      "Precision : 0.847\n",
      "Recall : 0.889\n",
      "F1 : 0.867\n"
     ]
    }
   ],
   "source": [
    "# modeling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_val_scaled)\n",
    "\n",
    "# 모델 성능평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_val, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_val, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_val, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_val, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96  8]\n",
      " [ 0  0]]\n",
      "Accuracy : 0.923\n",
      "Precision : 0.000\n",
      "Recall : 0.000\n",
      "F1 : 0.000\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 모델 성능평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[264   5]\n",
      " [  7  74]]\n",
      "Accuracy : 0.966\n",
      "Precision : 0.937\n",
      "Recall : 0.914\n",
      "F1 : 0.925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# fit\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = dt.predict(X_val_scaled)\n",
    "\n",
    "# 모델 성능평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_val, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "\n",
    "# score print\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_val, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_val, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_val, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93 11]\n",
      " [ 0  0]]\n",
      "Accuracy : 0.894\n",
      "Precision : 0.000\n",
      "Recall : 0.000\n",
      "F1 : 0.000\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "y_pred = dt.predict(X_test_scaled)\n",
    "\n",
    "# 모델 성능평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[256  13]\n",
      " [  7  74]]\n",
      "Accuracy : 0.943\n",
      "Precision : 0.851\n",
      "Recall : 0.914\n",
      "F1 : 0.881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(random_state=0, probability=True)\n",
    "\n",
    "# fit\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = svc.predict(X_val_scaled)\n",
    "\n",
    "# 모델 성능평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_val, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "\n",
    "# score print\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_val, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_val, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_val, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104]]\n",
      "Accuracy : 1.000\n",
      "Precision : 0.000\n",
      "Recall : 0.000\n",
      "F1 : 0.000\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "y_pred = svc.predict(X_test_scaled)\n",
    "\n",
    "# 모델 성능평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[265   4]\n",
      " [  7  74]]\n",
      "Accuracy : 0.969\n",
      "Precision : 0.949\n",
      "Recall : 0.914\n",
      "F1 : 0.931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# fit\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = rf_model.predict(X_val_scaled)\n",
    "\n",
    "# 모델 성능평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_val, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "\n",
    "# score print\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_val, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_val, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_val, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93 11]\n",
      " [ 0  0]]\n",
      "Accuracy : 0.894\n",
      "Precision : 0.000\n",
      "Recall : 0.000\n",
      "F1 : 0.000\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# 모델 성능평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[267   2]\n",
      " [  5  76]]\n",
      "Accuracy : 0.980\n",
      "Precision : 0.974\n",
      "Recall : 0.938\n",
      "F1 : 0.956\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "# fit\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = xgb_model.predict(X_val_scaled)\n",
    "\n",
    "\n",
    "# 모델 성능평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_val, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "# score print\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_val, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_val, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_val, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93 11]\n",
      " [ 0  0]]\n",
      "Accuracy : 0.894\n",
      "Precision : 0.000\n",
      "Recall : 0.000\n",
      "F1 : 0.000\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "y_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# 모델 성능평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 323, number of negative: 1077\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1242\n",
      "[LightGBM] [Info] Number of data points in the train set: 1400, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230714 -> initscore=-1.204282\n",
      "[LightGBM] [Info] Start training from score -1.204282\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[[268   1]\n",
      " [  5  76]]\n",
      "Accuracy : 0.983\n",
      "Precision : 0.987\n",
      "Recall : 0.938\n",
      "F1 : 0.962\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm_model = LGBMClassifier()\n",
    "\n",
    "# fit\n",
    "lgbm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = lgbm_model.predict(X_val_scaled)\n",
    "\n",
    "\n",
    "# 모델 성능평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_val, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "# score print\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_val, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_val, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_val, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87 17]\n",
      " [ 0  0]]\n",
      "Accuracy : 0.837\n",
      "Precision : 0.000\n",
      "Recall : 0.000\n",
      "F1 : 0.000\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "y_pred = lgbm_model.predict(X_test_scaled)\n",
    "\n",
    "# 모델 성능평가\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision : %.3f\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall : %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 : %.3f\" % f1_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
